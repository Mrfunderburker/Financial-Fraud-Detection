{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  i. Which insights did you gain from your EDA? \n",
    "From my EDA, I was able to figure out exactly what I was looking for and what I needed to focus on when it came to modeling. I discovered some correlations between fraud and other parameters that could be helpful in detecting fraud. I found the EDA to be a great starting point, and although it was difficult to get started, once I understood what to look for and how to delve deeper into the data, the rest seemed much clearer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. How did you determine which columns to drop or keep? If your EDA informed this process, explain which insights you used to determine which columns were not needed.\n",
    "*step,\tamount,\toldbalanceOrg,\tnewbalanceOrig,\toldbalanceDest, newbalanceDest, isFraud,    isFlaggedFraud*\n",
    "\n",
    "These were the columns, and from the EDA, I found that three had a higher correlation with fraud, so I determined these to be the most important and decided to keep them. I removed nameDest, nameOrig, and isFlaggedFraud because I felt these weren't necessary to continue with. There wasn't a high correlation between fraud and nameDest or nameOrig, so I dropped those. FlaggedFraud wasn't needed either because we need to develop a method for detecting fraud, and FlaggedFraud didnâ€™t contribute much to that process. I kept the other columns because I felt I could gain more insight from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Which hyperparameter tuning strategy did you use? Grid-search or random-search? Why? \n",
    "I used grid search (paramgrid) to tune the hyperparameters in my kNN model. This method works by trying out all the possible combinations of predefined hyperparameters to find the best one. Although it can take more time and resources, it guarantees that we find the best settings for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. How did your model's performance change after discovering optimal hyperparameters? \n",
    "After finding the best hyperparameters using grid search, the model performed better. The kNN model became more accurate at classifying the data. By adjusting settings like the number of neighbors (k), the model was able to make more balanced and reliable predictions. This led to better precision, recall, and F1 scores, especially for detecting fraud. Overall, tuning the hyperparameters made a noticeable difference in the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. What was your final F1 Score? \n",
    "Logistic Regression model: 0.55\n",
    "kNN model: 0.62\n",
    "Naive Bayes Model; 0.00\n",
    "The kNN model proved to be the best out of my 3 attempts at modeling with a score that wasnt all that impressive and leave a lot of room for improvement."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
